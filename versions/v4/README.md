多线程版本

待改进：csv提取临时线程文件夹里的json数据可能有遗漏

1. 先动态生成用户配置，抓取第一页获取总页数和总职位数

2. 遍历所有页面，请求间隔为1s，提取职位ID，根据配置项*page_progress_step*的间隔打印页面进度

3. 创建临时文件夹，以“时间_数量”命名，例如现在是2025-02-14 14:23:34，有23546个职位，则命名为20250214142334_23546

4. 反转ID列表，平均地交错地分配给所有线程，假如有6个线程：

   线程0：0,6,12,...；
   线程1：1,7,13,...；
   线程2：2,8,14,...；
   以此类推

5. 每个线程动态生成自己独立的用户配置，且维护自己独立的计数，根据配置的用户切换频率，计数一达到则重新动态生成自己独立的用户配置，且打印告知

6. 所有线程的执行时间序列，要遵循以下规律：
   假如有6个线程
   第一个3s:
   0s: 线程0
   0.5s: 线程1
   1s: 线程2
   1.5s: 线程3
   2s: 线程4
   2.5s: 线程5
   第二个3s:
   3s: 线程0
   3.5s: 线程1
   4s: 线程2
   4.5s: 线程3
   5s: 线程4
   5.5s: 线程5
   以此类推

7. 各个线程里的用户配置和该线程去jobsdb_job_details.py里抓取时的用户配置是要一致的

8. 各个线程根据*job_progress_step*配置的间隔各自打印职位进度

9. 先写入json文件，get_job_details返回有效数据且写入json文件成功时计入成功，否则计入失败，请求失败或者异常就打印哪个线程处理哪个id出现问题，然后记录失败的id，等所有线程完成任务后，统计成功和失败情况，然后主线程重新动态获取新的用户配置然后重试一次失败id的请求，成功则保存json到original_data文件夹里，失败则打印失败的id，最终将所有失败id保存到json文件，统计最终成功和失败的情况。最后再统一提取信息：逐个读取json文件，提取信息到csv文件里，统计成功和失败情况，提取信息失败则记录失败的json文件，等处理完所有json文件后再统一重试提取失败的json文件，统计最终成功和失败情况

10. 必须保证数据一致性，比如写入json失败时，如果创建了该失败的json文件就要及时删除该失败的文件，避免以为是完整的数据文件。提取数据写入csv也是类似。

11. 统计original_data文件夹里json文件数量与最终失败id数量，与一开始的初始数量做一致性检查并打印

12. 将临时文件夹重命名，以实际爬取数量即original_data文件夹里json文件数量为准，csv文件命名与文件夹相同